{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "d0e06eb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pprint\n",
    "import tempfile\n",
    "import pandas as pd\n",
    "\n",
    "from typing import Dict, Text\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow_recommenders as tfrs\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'  # 0 = all messages, 1 = INFO and WARNING, 2 = ERROR and WARNING, 3 = ERROR only\n",
    "\n",
    "import logging\n",
    "tf.get_logger().setLevel(logging.ERROR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f42e08f",
   "metadata": {},
   "source": [
    "### Data Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "78542eb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Skipping line 6452: expected 8 fields, saw 9\n",
      "Skipping line 43667: expected 8 fields, saw 10\n",
      "Skipping line 51751: expected 8 fields, saw 9\n",
      "Skipping line 92038: expected 8 fields, saw 9\n",
      "Skipping line 104319: expected 8 fields, saw 9\n",
      "Skipping line 121768: expected 8 fields, saw 9\n",
      "Skipping line 144058: expected 8 fields, saw 9\n",
      "Skipping line 150789: expected 8 fields, saw 9\n",
      "Skipping line 157128: expected 8 fields, saw 9\n",
      "Skipping line 180189: expected 8 fields, saw 9\n",
      "Skipping line 185738: expected 8 fields, saw 9\n",
      "Skipping line 209388: expected 8 fields, saw 9\n",
      "Skipping line 220626: expected 8 fields, saw 9\n",
      "Skipping line 227933: expected 8 fields, saw 11\n",
      "Skipping line 228957: expected 8 fields, saw 10\n",
      "Skipping line 245933: expected 8 fields, saw 9\n",
      "Skipping line 251296: expected 8 fields, saw 9\n",
      "Skipping line 259941: expected 8 fields, saw 9\n",
      "Skipping line 261529: expected 8 fields, saw 9\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Users\n",
    "u_cols = ['user_id', 'location', 'age']\n",
    "users = pd.read_csv('BX-CSV-Dump/BX-Users.csv', sep=';', encoding='latin-1', on_bad_lines='warn')\n",
    "\n",
    "#Books\n",
    "i_cols = ['isbn', 'book_title' ,'book_author','year_of_publication', 'publisher', 'img_s', 'img_m', 'img_l']\n",
    "items = pd.read_csv('BX-CSV-Dump/BX-Books.csv', sep=';', encoding='latin-1',low_memory=False, on_bad_lines='warn')\n",
    "\n",
    "#Ratings\n",
    "r_cols = ['user_id', 'isbn', 'rating']\n",
    "ratings = pd.read_csv('BX-CSV-Dump/BX-Book-Ratings.csv', sep=';', encoding='latin-1',low_memory=False, on_bad_lines='warn')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5577dc99",
   "metadata": {},
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "d339e357",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>user_age</th>\n",
       "      <th>user_country</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>34.751434</td>\n",
       "      <td>usa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>usa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>34.751434</td>\n",
       "      <td>russia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>portugal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>34.751434</td>\n",
       "      <td>united kingdom</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  user_id   user_age     user_country\n",
       "0       1  34.751434              usa\n",
       "1       2  18.000000              usa\n",
       "2       3  34.751434           russia\n",
       "3       4  17.000000         portugal\n",
       "4       5  34.751434   united kingdom"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "users = users.join(users['Location'].str.split(',', 2, expand=True).rename(columns={0:'City', 1:'Region', 2:'Country'}))\n",
    "users['Country'] = users['Country'].fillna('usa')\n",
    "users['Age'] = users['Age'].fillna(np.mean(users['Age']))\n",
    "users.drop(columns=['City', 'Region', 'Location'], inplace=True)\n",
    "users['User-ID'] = users['User-ID'].astype('str')\n",
    "users.rename(columns={'User-ID':'user_id', 'Age':'user_age', 'Country':'user_country'}, inplace=True)\n",
    "users.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "3b00427b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>book_id</th>\n",
       "      <th>book_title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0195153448</td>\n",
       "      <td>Classical Mythology</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0002005018</td>\n",
       "      <td>Clara Callan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0060973129</td>\n",
       "      <td>Decision in Normandy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0374157065</td>\n",
       "      <td>Flu: The Story of the Great Influenza Pandemic...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0393045218</td>\n",
       "      <td>The Mummies of Urumchi</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      book_id                                         book_title\n",
       "0  0195153448                                Classical Mythology\n",
       "1  0002005018                                       Clara Callan\n",
       "2  0060973129                               Decision in Normandy\n",
       "3  0374157065  Flu: The Story of the Great Influenza Pandemic...\n",
       "4  0393045218                             The Mummies of Urumchi"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "items = items[['ISBN', 'Book-Title']]\n",
    "items.rename(columns={'ISBN':'book_id', 'Book-Title':'book_title'}, inplace=True)\n",
    "items.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "00ba5bbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "items_100000 = items.sample(n=100000)\n",
    "users_10000 = users.sample(n=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "8e51e296",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# Function to generate a random date between the specified range\n",
    "def random_date(start, end):\n",
    "    delta = end - start\n",
    "    random_days = random.randrange(delta.days)\n",
    "    return start + timedelta(days=random_days)\n",
    "\n",
    "# Set the date range\n",
    "start_date = datetime(2020, 1, 1)\n",
    "end_date = datetime(2022, 1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "656ba732",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>book_id</th>\n",
       "      <th>Book-Rating</th>\n",
       "      <th>user_age</th>\n",
       "      <th>user_country</th>\n",
       "      <th>book_title</th>\n",
       "      <th>rating_timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>276788</td>\n",
       "      <td>055310666X</td>\n",
       "      <td>10</td>\n",
       "      <td>34.751434</td>\n",
       "      <td>usa</td>\n",
       "      <td>False Memory</td>\n",
       "      <td>1.583280e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133</th>\n",
       "      <td>276822</td>\n",
       "      <td>0060096195</td>\n",
       "      <td>10</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>canada</td>\n",
       "      <td>The Boy Next Door</td>\n",
       "      <td>1.594426e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134</th>\n",
       "      <td>276822</td>\n",
       "      <td>0141310340</td>\n",
       "      <td>9</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>canada</td>\n",
       "      <td>Skin and Other Stories (Now in Speak!)</td>\n",
       "      <td>1.602374e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137</th>\n",
       "      <td>276822</td>\n",
       "      <td>0375821813</td>\n",
       "      <td>9</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>canada</td>\n",
       "      <td>Hoot (Newbery Honor Book)</td>\n",
       "      <td>1.600387e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>276822</td>\n",
       "      <td>0439401399</td>\n",
       "      <td>6</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>canada</td>\n",
       "      <td>The Contest</td>\n",
       "      <td>1.604362e+09</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    user_id     book_id  Book-Rating   user_age user_country  \\\n",
       "85   276788  055310666X           10  34.751434          usa   \n",
       "133  276822  0060096195           10  11.000000       canada   \n",
       "134  276822  0141310340            9  11.000000       canada   \n",
       "137  276822  0375821813            9  11.000000       canada   \n",
       "140  276822  0439401399            6  11.000000       canada   \n",
       "\n",
       "                                 book_title  rating_timestamp  \n",
       "85                             False Memory      1.583280e+09  \n",
       "133                       The Boy Next Door      1.594426e+09  \n",
       "134  Skin and Other Stories (Now in Speak!)      1.602374e+09  \n",
       "137               Hoot (Newbery Honor Book)      1.600387e+09  \n",
       "140                             The Contest      1.604362e+09  "
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings.rename(columns={'User-ID':'user_id', 'ISBN':'book_id'}, inplace=True)\n",
    "ratings['user_id'] = ratings['user_id'].astype('str')\n",
    "ratings_df = pd.merge(ratings, users_10000, on='user_id', how='left')\n",
    "ratings_df = pd.merge(ratings_df, items_100000, on='book_id', how='left')\n",
    "ratings_df.dropna(inplace=True)\n",
    "ratings_df['rating_timestamp'] = [random_date(start_date, end_date) for _ in range(len(ratings_df))]\n",
    "ratings_df['rating_timestamp'] = ratings_df['rating_timestamp'].apply(lambda x: x.timestamp())\n",
    "ratings_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "01395813",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Users:  1913\n",
      "Total Books:  9506\n",
      "Total Interactions:  13565\n"
     ]
    }
   ],
   "source": [
    "print('Total Users: ', ratings_df.user_id.nunique())\n",
    "print('Total Books: ', ratings_df.book_id.nunique())\n",
    "print('Total Interactions: ', ratings_df.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "44dbe0b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_ratings = tf.data.Dataset.from_tensor_slices(dict(ratings_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "795a2932",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_ratings_map = tf_ratings.map(lambda x: {\n",
    "    \"book_id\": x[\"book_id\"],\n",
    "    \"user_id\": x[\"user_id\"],\n",
    "    \"user_rating\": x[\"Book-Rating\"],\n",
    "    \"user_age\": x[\"user_age\"],\n",
    "    \"user_country\": x[\"user_country\"],\n",
    "    \"book_title\": x[\"book_title\"],\n",
    "    \"rating_timestamp\": x[\"rating_timestamp\"]\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "d953f5d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "book_ids = tf_ratings_map.batch(10_000).map(lambda x: x[\"book_id\"])\n",
    "book_titles = tf_ratings_map.batch(10_000).map(lambda x: x[\"book_title\"])\n",
    "user_ids = tf_ratings_map.batch(10_000).map(lambda x: x[\"user_id\"])\n",
    "user_countries = tf_ratings_map.batch(10_000).map(lambda x: x[\"user_country\"])\n",
    "\n",
    "unique_book_ids = np.unique(np.concatenate(list(book_ids)))\n",
    "unique_book_titles = np.unique(np.concatenate(list(book_titles)))\n",
    "unique_user_ids = np.unique(np.concatenate(list(user_ids)))\n",
    "unique_user_countries = np.unique(np.concatenate(list(user_countries)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "76f92fdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Randomly shuffle data and split between train and test.\n",
    "tf.random.set_seed(42)\n",
    "shuffled = tf_ratings_map.shuffle(15_00_000, seed=42, reshuffle_each_iteration=False)\n",
    "\n",
    "train = shuffled.take(10_000)\n",
    "test = shuffled.skip(10_000).take(4_000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "2bf74a59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Buckets: [ 0.          4.31578947  8.63157895 12.94736842 17.26315789 21.57894737\n",
      " 25.89473684 30.21052632 34.52631579 38.84210526 43.15789474 47.47368421\n",
      " 51.78947368 56.10526316 60.42105263 64.73684211 69.05263158 73.36842105\n",
      " 77.68421053 82.        ]\n"
     ]
    }
   ],
   "source": [
    "max_age = tf_ratings_map.map(lambda x: x[\"user_age\"]).reduce(\n",
    "    tf.cast(0, tf.float64), tf.maximum).numpy().max()\n",
    "min_age = tf_ratings_map.map(lambda x: x[\"user_age\"]).reduce(\n",
    "    tf.cast(0, tf.float64), tf.minimum).numpy().min()\n",
    "\n",
    "age_buckets = np.linspace(\n",
    "    min_age, max_age, num=20)\n",
    "\n",
    "print(f\"Buckets: {age_buckets}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "7589fca1",
   "metadata": {},
   "outputs": [],
   "source": [
    "timestamps = np.concatenate(list(tf_ratings_map.map(lambda x: x[\"rating_timestamp\"]).batch(100)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f65d5d8e",
   "metadata": {},
   "source": [
    "### User Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "ae696201",
   "metadata": {},
   "outputs": [],
   "source": [
    "class UserModel(tf.keras.Model):\n",
    "  \n",
    "    def __init__(self, unique_user_ids, unique_user_countries, age_buckets, timestamps, embedding_dimension):\n",
    "        super().__init__()\n",
    "\n",
    "        self.user_embedding = tf.keras.Sequential([\n",
    "            tf.keras.layers.StringLookup(\n",
    "                vocabulary=unique_user_ids, mask_token=None),\n",
    "            tf.keras.layers.Embedding(len(unique_user_ids) + 1, embedding_dimension),\n",
    "        ])\n",
    "        \n",
    "        self.country_embedding = tf.keras.Sequential([\n",
    "            tf.keras.layers.StringLookup(\n",
    "                vocabulary=unique_user_countries, mask_token=None),\n",
    "            tf.keras.layers.Embedding(len(unique_user_countries) + 1, embedding_dimension),\n",
    "        ])\n",
    "        \n",
    "        self.age_embedding = tf.keras.Sequential([\n",
    "            tf.keras.layers.Discretization(age_buckets.tolist()),\n",
    "            tf.keras.layers.Embedding(len(age_buckets) + 2, embedding_dimension)\n",
    "        ])\n",
    "        \n",
    "        self.normalized_timestamp = tf.keras.layers.Normalization(\n",
    "            axis=None\n",
    "        )\n",
    "\n",
    "        self.normalized_timestamp.adapt(timestamps)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        # Take the input dictionary, pass it through each input layer,\n",
    "        # and concatenate the result.\n",
    "        return tf.concat([\n",
    "            self.user_embedding(inputs[\"user_id\"]),\n",
    "            self.country_embedding(inputs[\"user_country\"]),\n",
    "            self.age_embedding(inputs[\"user_age\"]),\n",
    "            tf.reshape(self.normalized_timestamp(inputs[\"rating_timestamp\"]), (-1, 1)),\n",
    "        ], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "822f80f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computed representations: [[-9.49854776e-03 -4.07686941e-02 -2.75819302e-02 -1.08468533e-02\n",
      "   1.68311596e-03 -3.94163243e-02 -1.70231946e-02  3.36598493e-02\n",
      "   1.80847533e-02  4.65952642e-02 -2.80122831e-03 -4.25349548e-03\n",
      "  -2.30829008e-02  4.36505191e-02  3.44716348e-02 -9.02016088e-03\n",
      "  -6.28281757e-03 -1.50293820e-02  1.89254321e-02  2.02165581e-02\n",
      "   3.95418331e-03 -8.76940787e-04 -2.05943733e-03 -4.15004417e-03\n",
      "   3.34905125e-02 -2.91977767e-02 -4.43983078e-02 -2.34945416e-02\n",
      "  -9.03869793e-03  1.97106712e-02  7.85908848e-03 -2.27237474e-02\n",
      "   1.72722600e-02  3.39537300e-02 -9.18791443e-03  3.42808031e-02\n",
      "   1.35832094e-02 -2.77657267e-02 -4.61349487e-02 -9.73738357e-03\n",
      "   4.29556631e-02 -1.66180246e-02 -1.91069134e-02 -1.79636367e-02\n",
      "  -9.02209431e-03 -2.95696147e-02 -4.21343558e-02 -1.76161155e-02\n",
      "  -1.42933242e-02 -7.78484344e-03  2.90289186e-02  3.47695686e-02\n",
      "  -2.63884068e-02  4.00923565e-03 -2.86171678e-02  2.55995877e-02\n",
      "  -1.11088753e-02 -1.04076788e-03 -9.56403092e-03 -2.93138623e-02\n",
      "   1.85588710e-02  3.85265090e-02 -1.91994067e-02 -4.78784814e-02\n",
      "  -3.29030305e-02  4.31461968e-02 -3.39385420e-02  3.29282992e-02\n",
      "  -4.75285165e-02  1.50652565e-02  4.22184803e-02  8.57815892e-03\n",
      "  -2.39859577e-02 -4.72982526e-02 -9.85912234e-03  3.58550623e-03\n",
      "   4.65688966e-02  2.01879479e-02 -4.42212708e-02  4.29975875e-02\n",
      "   8.82167742e-03 -9.57927853e-03 -1.91695336e-02  2.98458226e-02\n",
      "  -4.92595434e-02  3.76463197e-02  3.90799381e-02  1.25194825e-02\n",
      "   3.61140110e-02  3.07668708e-02 -2.19375249e-02 -4.27329317e-02\n",
      "   2.15389580e-03 -2.21760198e-03 -1.00331791e-02  2.16982625e-02\n",
      "  -1.41349232e+00]]\n"
     ]
    }
   ],
   "source": [
    "user_model = UserModel(unique_user_ids, unique_user_countries, age_buckets, timestamps, 32)\n",
    "for row in tf_ratings_map.batch(1).take(1):\n",
    "    print(f\"Computed representations: {user_model(row)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "083a59e6",
   "metadata": {},
   "source": [
    "### Book Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "2d24e1fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BookModel(tf.keras.Model):\n",
    "\n",
    "    def __init__(self, unique_book_ids, unique_book_titles, embedding_dimension):\n",
    "        super().__init__()\n",
    "\n",
    "        max_tokens = 1_000\n",
    "\n",
    "        self.book_embedding = tf.keras.Sequential([\n",
    "            tf.keras.layers.StringLookup(\n",
    "                vocabulary=unique_book_ids, mask_token=None),\n",
    "            tf.keras.layers.Embedding(len(unique_book_ids) + 1, embedding_dimension),\n",
    "        ])\n",
    "    \n",
    "        self.title_vectorizer = tf.keras.layers.TextVectorization(\n",
    "            max_tokens=max_tokens)\n",
    "\n",
    "        self.title_embedding = tf.keras.Sequential([\n",
    "          self.title_vectorizer,\n",
    "          tf.keras.layers.Embedding(max_tokens, 32, mask_zero=True),\n",
    "          tf.keras.layers.GlobalAveragePooling1D(),\n",
    "        ])\n",
    "\n",
    "        self.title_vectorizer.adapt(unique_book_titles)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        return tf.concat([\n",
    "            self.book_embedding(inputs[\"book_id\"]),\n",
    "            self.title_embedding(inputs[\"book_title\"]),\n",
    "        ], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "52ad7bc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computed representations: [[-3.94688137e-02 -3.75805497e-02 -4.79060411e-02 -7.67754391e-03\n",
      "  -3.76792662e-02 -4.33177464e-02  3.94165181e-02 -1.28926039e-02\n",
      "  -1.48759596e-02 -9.29572433e-03  7.58085400e-03  2.11796500e-02\n",
      "  -3.00803427e-02  2.42065303e-02  2.30334513e-02 -4.81771007e-02\n",
      "  -1.72335282e-02  2.25508846e-02  2.93181427e-02  1.00679025e-02\n",
      "   3.37586142e-02  2.99189351e-02 -1.54346451e-02 -4.27184589e-02\n",
      "  -3.38370204e-02  4.85745184e-02 -2.58558281e-02  3.24600972e-02\n",
      "   1.80996768e-02  3.45756859e-03  4.76169847e-02 -4.66955565e-02\n",
      "   1.54240150e-02  4.19015065e-04  1.87681783e-02 -8.50616023e-04\n",
      "   5.78434486e-03  1.43453684e-02 -1.58941802e-02 -2.46956851e-03\n",
      "  -1.01527553e-02  5.24986535e-04  1.43242022e-02 -2.59545520e-02\n",
      "   1.99114010e-02  1.32593140e-03 -1.21377120e-02  6.47782162e-03\n",
      "  -2.29139216e-02 -9.08130966e-03  9.33548622e-03  2.77774408e-04\n",
      "  -3.12197953e-05 -4.70387712e-02  3.63731757e-04  3.42994221e-02\n",
      "   2.10731905e-02 -9.61798523e-03 -1.21891387e-02 -4.53553163e-03\n",
      "   3.69501598e-02 -3.93587276e-02  3.75085659e-02 -3.11465822e-02]]\n"
     ]
    }
   ],
   "source": [
    "book_model = BookModel(unique_book_ids, unique_book_titles, 32)\n",
    "for row in tf_ratings_map.batch(1).take(1):\n",
    "    print(f\"Computed representations: {book_model(row)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bce930b2",
   "metadata": {},
   "source": [
    "### Book Recommender Model with Rating and Retrival tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "02d62cd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_books = tf.data.Dataset.from_tensor_slices(dict(items_100000))\n",
    "tf_books_map = tf_books.map(lambda x: {\n",
    "    \"book_id\": x[\"book_id\"], \n",
    "    \"book_title\": x[\"book_title\"]\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "ec064243",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BookRecModel(tfrs.models.Model):\n",
    "\n",
    "    def __init__(self, rating_weight, retrieval_weight, unique_user_ids, unique_user_countries, \n",
    "                 unique_book_ids, unique_book_titles, age_buckets, timestamps):\n",
    "        super().__init__()\n",
    "\n",
    "        embedding_dimension = 32\n",
    "        \n",
    "        self.user_model = tf.keras.Sequential([\n",
    "            UserModel(unique_user_ids, unique_user_countries, age_buckets, timestamps, embedding_dimension),\n",
    "            tf.keras.layers.Dense(embedding_dimension)\n",
    "        ])\n",
    "        \n",
    "        self.book_model = tf.keras.Sequential([\n",
    "            BookModel(unique_book_ids, unique_book_titles, embedding_dimension),\n",
    "            tf.keras.layers.Dense(embedding_dimension)\n",
    "        ])\n",
    "        \n",
    "        self.rating_model = tf.keras.Sequential([\n",
    "            tf.keras.layers.Dense(256, activation=\"relu\"),\n",
    "            tf.keras.layers.Dense(128, activation=\"relu\"),\n",
    "            tf.keras.layers.Dense(1),\n",
    "        ])\n",
    "        \n",
    "        self.rating_task: tf.keras.layers.Layer = tfrs.tasks.Ranking(\n",
    "            loss=tf.keras.losses.MeanSquaredError(),\n",
    "            metrics=[tf.keras.metrics.RootMeanSquaredError()],\n",
    "        )\n",
    "            \n",
    "        self.retrieval_task: tf.keras.layers.Layer = tfrs.tasks.Retrieval(\n",
    "            metrics=tfrs.metrics.FactorizedTopK(\n",
    "                candidates = tf_books_map.batch(128).map(self.book_model)\n",
    "            )\n",
    "        )\n",
    "\n",
    "        # The loss weights.\n",
    "        self.rating_weight = rating_weight\n",
    "        self.retrieval_weight = retrieval_weight\n",
    "\n",
    "    def call(self, features: Dict[Text, tf.Tensor]) -> tf.Tensor:        \n",
    "        user_embeddings = self.user_model(features)\n",
    "        book_embeddings = self.book_model(features)\n",
    "\n",
    "        return (\n",
    "            user_embeddings,\n",
    "            book_embeddings,\n",
    "\n",
    "            self.rating_model(\n",
    "                tf.concat([user_embeddings, book_embeddings], axis=1)\n",
    "            ),\n",
    "        )\n",
    "\n",
    "    def compute_loss(self, features: Dict[Text, tf.Tensor], training=False) -> tf.Tensor:\n",
    "\n",
    "        ratings = features.pop(\"user_rating\")\n",
    "\n",
    "        user_embeddings, book_embeddings, rating_predictions = self(features)\n",
    "\n",
    "        # We compute the loss for each task.\n",
    "        rating_loss = self.rating_task(\n",
    "            labels=ratings,\n",
    "            predictions=rating_predictions,\n",
    "        )\n",
    "        retrieval_loss = self.retrieval_task(user_embeddings, book_embeddings)\n",
    "\n",
    "        # And combine them using the loss weights.\n",
    "        return (self.rating_weight * rating_loss\n",
    "                + self.retrieval_weight * retrieval_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "c784849c",
   "metadata": {},
   "outputs": [],
   "source": [
    "cached_train = train.shuffle(100_000).batch(2048)\n",
    "cached_test = test.batch(4096).cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "a66056df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor. Received: inputs={'book_id': <tf.Tensor 'args_0:0' shape=(None,) dtype=string>, 'book_title': <tf.Tensor 'args_1:0' shape=(None,) dtype=string>}. Consider rewriting this model with the Functional API.\n"
     ]
    }
   ],
   "source": [
    "model = BookRecModel(0.5, 0.5, unique_user_ids, unique_user_countries, unique_book_ids, \n",
    "                     unique_book_titles, age_buckets, unique_user_age)\n",
    "model.compile(optimizer=tf.keras.optimizers.Adagrad(0.1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "a68cf283",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor. Received: inputs={'book_id': <tf.Tensor 'IteratorGetNext:0' shape=(None,) dtype=string>, 'user_id': <tf.Tensor 'IteratorGetNext:5' shape=(None,) dtype=string>, 'user_age': <tf.Tensor 'book_rec_model_9/Cast_1:0' shape=(None,) dtype=float32>, 'user_country': <tf.Tensor 'IteratorGetNext:4' shape=(None,) dtype=string>, 'book_title': <tf.Tensor 'IteratorGetNext:1' shape=(None,) dtype=string>, 'rating_timestamp': <tf.Tensor 'book_rec_model_9/Cast:0' shape=(None,) dtype=float32>}. Consider rewriting this model with the Functional API.\n",
      "WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor. Received: inputs={'book_id': <tf.Tensor 'IteratorGetNext:0' shape=(None,) dtype=string>, 'user_id': <tf.Tensor 'IteratorGetNext:5' shape=(None,) dtype=string>, 'user_age': <tf.Tensor 'book_rec_model_9/Cast_1:0' shape=(None,) dtype=float32>, 'user_country': <tf.Tensor 'IteratorGetNext:4' shape=(None,) dtype=string>, 'book_title': <tf.Tensor 'IteratorGetNext:1' shape=(None,) dtype=string>, 'rating_timestamp': <tf.Tensor 'book_rec_model_9/Cast:0' shape=(None,) dtype=float32>}. Consider rewriting this model with the Functional API.\n",
      "WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor. Received: inputs={'book_id': <tf.Tensor 'IteratorGetNext:0' shape=(None,) dtype=string>, 'user_id': <tf.Tensor 'IteratorGetNext:5' shape=(None,) dtype=string>, 'user_age': <tf.Tensor 'book_rec_model_9/Cast_1:0' shape=(None,) dtype=float32>, 'user_country': <tf.Tensor 'IteratorGetNext:4' shape=(None,) dtype=string>, 'book_title': <tf.Tensor 'IteratorGetNext:1' shape=(None,) dtype=string>, 'rating_timestamp': <tf.Tensor 'book_rec_model_9/Cast:0' shape=(None,) dtype=float32>}. Consider rewriting this model with the Functional API.\n",
      "WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor. Received: inputs={'book_id': <tf.Tensor 'IteratorGetNext:0' shape=(None,) dtype=string>, 'user_id': <tf.Tensor 'IteratorGetNext:5' shape=(None,) dtype=string>, 'user_age': <tf.Tensor 'book_rec_model_9/Cast_1:0' shape=(None,) dtype=float32>, 'user_country': <tf.Tensor 'IteratorGetNext:4' shape=(None,) dtype=string>, 'book_title': <tf.Tensor 'IteratorGetNext:1' shape=(None,) dtype=string>, 'rating_timestamp': <tf.Tensor 'book_rec_model_9/Cast:0' shape=(None,) dtype=float32>}. Consider rewriting this model with the Functional API.\n",
      "5/5 [==============================] - 12s 2s/step - root_mean_squared_error: 735315136.0000 - factorized_top_k/top_1_categorical_accuracy: 0.0290 - factorized_top_k/top_5_categorical_accuracy: 0.0335 - factorized_top_k/top_10_categorical_accuracy: 0.0346 - factorized_top_k/top_50_categorical_accuracy: 0.0416 - factorized_top_k/top_100_categorical_accuracy: 0.0461 - loss: 220015339529480864.0000 - regularization_loss: 0.0000e+00 - total_loss: 220015339529480864.0000           \n",
      "Epoch 2/3\n",
      "5/5 [==============================] - 11s 2s/step - root_mean_squared_error: 4183352.0000 - factorized_top_k/top_1_categorical_accuracy: 0.0711 - factorized_top_k/top_5_categorical_accuracy: 0.0791 - factorized_top_k/top_10_categorical_accuracy: 0.0845 - factorized_top_k/top_50_categorical_accuracy: 0.1028 - factorized_top_k/top_100_categorical_accuracy: 0.1159 - loss: 7184078135296.0000 - regularization_loss: 0.0000e+00 - total_loss: 7184078135296.0000\n",
      "Epoch 3/3\n",
      "5/5 [==============================] - 11s 2s/step - root_mean_squared_error: 67325.6719 - factorized_top_k/top_1_categorical_accuracy: 0.1021 - factorized_top_k/top_5_categorical_accuracy: 0.1026 - factorized_top_k/top_10_categorical_accuracy: 0.1045 - factorized_top_k/top_50_categorical_accuracy: 0.1333 - factorized_top_k/top_100_categorical_accuracy: 0.1453 - loss: 39563020970.6667 - regularization_loss: 0.0000e+00 - total_loss: 39563020970.6667\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1a2a714fa00>"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(cached_train, epochs=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "f45e028b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 4s 4s/step - root_mean_squared_error: 4581.2241 - factorized_top_k/top_1_categorical_accuracy: 2.8050e-04 - factorized_top_k/top_5_categorical_accuracy: 2.8050e-04 - factorized_top_k/top_10_categorical_accuracy: 8.4151e-04 - factorized_top_k/top_50_categorical_accuracy: 0.0031 - factorized_top_k/top_100_categorical_accuracy: 0.0067 - loss: 63541108736.0000 - regularization_loss: 0.0000e+00 - total_loss: 63541108736.0000\n",
      "Retrieval top-100 accuracy: 0.007.\n",
      "Ranking RMSE: 4581.224.\n"
     ]
    }
   ],
   "source": [
    "metrics = model.evaluate(cached_test, return_dict=True)\n",
    "\n",
    "print(f\"Retrieval top-100 accuracy: {metrics['factorized_top_k/top_100_categorical_accuracy']:.3f}.\")\n",
    "print(f\"Ranking RMSE: {metrics['root_mean_squared_error']:.3f}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb5af70c",
   "metadata": {},
   "source": [
    "### Recommendation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "0493ecc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"book_rec_model_9\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " sequential_110 (Sequential)  multiple                 67043     \n",
      "                                                                 \n",
      " sequential_113 (Sequential)  multiple                 338304    \n",
      "                                                                 \n",
      " sequential_114 (Sequential)  (None, 1)                49665     \n",
      "                                                                 \n",
      " ranking_9 (Ranking)         multiple                  0         \n",
      "                                                                 \n",
      " retrieval_9 (Retrieval)     multiple                  1         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 455,013\n",
      "Trainable params: 455,009\n",
      "Non-trainable params: 4\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "faa54d59",
   "metadata": {},
   "outputs": [],
   "source": [
    "brute_force = tfrs.layers.factorized_top_k.BruteForce(model.user_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "b88d26c4",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    File \"C:\\Users\\awast\\AppData\\Local\\Temp\\ipykernel_79924\\1463076740.py\", line 2, in None  *\n        lambda x: {\"book_embedding\": model.book_model(x), \"book_id\": x[\"book_id\"]}\n    File \"C:\\Users\\awast\\.conda\\envs\\tf\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 70, in error_handler  **\n        raise e.with_traceback(filtered_tb) from None\n    File \"C:\\Users\\awast\\AppData\\Local\\Temp\\__autograph_generated_filedywseif7.py\", line 12, in tf__call\n        retval_ = ag__.converted_call(ag__.ld(tf).concat, ([ag__.converted_call(ag__.ld(self).book_embedding, (ag__.ld(inputs)['book_id'],), None, fscope), ag__.converted_call(ag__.ld(self).title_embedding, (ag__.ld(inputs)['book_title'],), None, fscope)],), dict(axis=1), fscope)\n\n    ValueError: Exception encountered when calling layer 'book_model_16' (type BookModel).\n    \n    in user code:\n    \n        File \"C:\\Users\\awast\\AppData\\Local\\Temp\\ipykernel_79924\\948094142.py\", line 28, in call  *\n            self.title_embedding(inputs[\"book_title\"]),\n        File \"C:\\Users\\awast\\.conda\\envs\\tf\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 70, in error_handler  **\n            raise e.with_traceback(filtered_tb) from None\n        File \"C:\\Users\\awast\\.conda\\envs\\tf\\lib\\site-packages\\keras\\engine\\input_spec.py\", line 235, in assert_input_compatibility\n            raise ValueError(\n    \n        ValueError: Exception encountered when calling layer 'sequential_112' (type Sequential).\n        \n        Input 0 of layer \"global_average_pooling1d_10\" is incompatible with the layer: expected ndim=3, found ndim=2. Full shape received: (None, 32)\n        \n        Call arguments received by layer 'sequential_112' (type Sequential):\n          • inputs=tf.Tensor(shape=(), dtype=string)\n          • training=None\n          • mask=None\n    \n    \n    Call arguments received by layer 'book_model_16' (type BookModel):\n      • inputs={'book_id': 'tf.Tensor(shape=(), dtype=string)', 'book_title': 'tf.Tensor(shape=(), dtype=string)'}\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[181], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Transform book titles into embeddings using the book_model\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m test_map \u001b[38;5;241m=\u001b[39m \u001b[43mtf_books_map\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mbook_embedding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbook_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mbook_id\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mbook_id\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# Use 'index_from_dataset'\u001b[39;00m\n\u001b[0;32m      5\u001b[0m index\u001b[38;5;241m.\u001b[39mindex_from_dataset(\n\u001b[0;32m      6\u001b[0m     tf_books_map\u001b[38;5;241m.\u001b[39mbatch(\u001b[38;5;241m100\u001b[39m)\u001b[38;5;241m.\u001b[39mmap(\u001b[38;5;28;01mlambda\u001b[39;00m x: (x[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbook_title\u001b[39m\u001b[38;5;124m\"\u001b[39m], x[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbook_id\u001b[39m\u001b[38;5;124m\"\u001b[39m]))\n\u001b[0;32m      7\u001b[0m )\n",
      "File \u001b[1;32m~\\.conda\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\data\\ops\\dataset_ops.py:2240\u001b[0m, in \u001b[0;36mDatasetV2.map\u001b[1;34m(self, map_func, num_parallel_calls, deterministic, name)\u001b[0m\n\u001b[0;32m   2236\u001b[0m \u001b[38;5;66;03m# Loaded lazily due to a circular dependency (dataset_ops -> map_op ->\u001b[39;00m\n\u001b[0;32m   2237\u001b[0m \u001b[38;5;66;03m# dataset_ops).\u001b[39;00m\n\u001b[0;32m   2238\u001b[0m \u001b[38;5;66;03m# pylint: disable=g-import-not-at-top,protected-access\u001b[39;00m\n\u001b[0;32m   2239\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mops\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m map_op\n\u001b[1;32m-> 2240\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmap_op\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_map_v2\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2241\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2242\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmap_func\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2243\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_parallel_calls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_parallel_calls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2244\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdeterministic\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdeterministic\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2245\u001b[0m \u001b[43m    \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\.conda\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\data\\ops\\map_op.py:37\u001b[0m, in \u001b[0;36m_map_v2\u001b[1;34m(input_dataset, map_func, num_parallel_calls, deterministic, name)\u001b[0m\n\u001b[0;32m     34\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m deterministic \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m debug_mode\u001b[38;5;241m.\u001b[39mDEBUG_MODE:\n\u001b[0;32m     35\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe `deterministic` argument has no effect unless the \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     36\u001b[0m                   \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`num_parallel_calls` argument is specified.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 37\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_MapDataset\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     38\u001b[0m \u001b[43m      \u001b[49m\u001b[43minput_dataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmap_func\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpreserve_cardinality\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     39\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     40\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m _ParallelMapDataset(\n\u001b[0;32m     41\u001b[0m       input_dataset,\n\u001b[0;32m     42\u001b[0m       map_func,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     45\u001b[0m       preserve_cardinality\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m     46\u001b[0m       name\u001b[38;5;241m=\u001b[39mname)\n",
      "File \u001b[1;32m~\\.conda\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\data\\ops\\map_op.py:107\u001b[0m, in \u001b[0;36m_MapDataset.__init__\u001b[1;34m(self, input_dataset, map_func, use_inter_op_parallelism, preserve_cardinality, use_legacy_function, name)\u001b[0m\n\u001b[0;32m    105\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_use_inter_op_parallelism \u001b[38;5;241m=\u001b[39m use_inter_op_parallelism\n\u001b[0;32m    106\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_preserve_cardinality \u001b[38;5;241m=\u001b[39m preserve_cardinality\n\u001b[1;32m--> 107\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_map_func \u001b[38;5;241m=\u001b[39m \u001b[43mstructured_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mStructuredFunctionWrapper\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    108\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmap_func\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    109\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_transformation_name\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    110\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdataset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_dataset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    111\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_legacy_function\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_legacy_function\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    112\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_name \u001b[38;5;241m=\u001b[39m name\n\u001b[0;32m    113\u001b[0m variant_tensor \u001b[38;5;241m=\u001b[39m gen_dataset_ops\u001b[38;5;241m.\u001b[39mmap_dataset(\n\u001b[0;32m    114\u001b[0m     input_dataset\u001b[38;5;241m.\u001b[39m_variant_tensor,  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m    115\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_map_func\u001b[38;5;241m.\u001b[39mfunction\u001b[38;5;241m.\u001b[39mcaptured_inputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    118\u001b[0m     preserve_cardinality\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_preserve_cardinality,\n\u001b[0;32m    119\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_common_args)\n",
      "File \u001b[1;32m~\\.conda\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\data\\ops\\structured_function.py:261\u001b[0m, in \u001b[0;36mStructuredFunctionWrapper.__init__\u001b[1;34m(self, func, transformation_name, dataset, input_classes, input_shapes, input_types, input_structure, add_to_graph, use_legacy_function, defun_kwargs)\u001b[0m\n\u001b[0;32m    254\u001b[0m       warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m    255\u001b[0m           \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEven though the `tf.config.experimental_run_functions_eagerly` \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    256\u001b[0m           \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moption is set, this option does not apply to tf.data functions. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    257\u001b[0m           \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTo force eager execution of tf.data functions, please use \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    258\u001b[0m           \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`tf.data.experimental.enable_debug_mode()`.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    259\u001b[0m     fn_factory \u001b[38;5;241m=\u001b[39m trace_tf_function(defun_kwargs)\n\u001b[1;32m--> 261\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_function \u001b[38;5;241m=\u001b[39m \u001b[43mfn_factory\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    262\u001b[0m \u001b[38;5;66;03m# There is no graph to add in eager mode.\u001b[39;00m\n\u001b[0;32m    263\u001b[0m add_to_graph \u001b[38;5;241m&\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m context\u001b[38;5;241m.\u001b[39mexecuting_eagerly()\n",
      "File \u001b[1;32m~\\.conda\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compiler.py:232\u001b[0m, in \u001b[0;36mTracingCompiler.get_concrete_function\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    223\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_concrete_function\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m    224\u001b[0m   \u001b[38;5;124;03m\"\"\"Returns a `ConcreteFunction` specialized to inputs and execution context.\u001b[39;00m\n\u001b[0;32m    225\u001b[0m \n\u001b[0;32m    226\u001b[0m \u001b[38;5;124;03m  Args:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    230\u001b[0m \u001b[38;5;124;03m      `tf.Tensor` or `tf.TensorSpec`.\u001b[39;00m\n\u001b[0;32m    231\u001b[0m \u001b[38;5;124;03m  \"\"\"\u001b[39;00m\n\u001b[1;32m--> 232\u001b[0m   concrete_function \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_concrete_function_garbage_collected(\n\u001b[0;32m    233\u001b[0m       \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    234\u001b[0m   concrete_function\u001b[38;5;241m.\u001b[39m_garbage_collector\u001b[38;5;241m.\u001b[39mrelease()  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m    235\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m concrete_function\n",
      "File \u001b[1;32m~\\.conda\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compiler.py:202\u001b[0m, in \u001b[0;36mTracingCompiler._get_concrete_function_garbage_collected\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    199\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_function_spec\u001b[38;5;241m.\u001b[39mmake_canonicalized_monomorphic_type(args, kwargs)\n\u001b[0;32m    201\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[1;32m--> 202\u001b[0m   concrete_function, _ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_maybe_define_concrete_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    203\u001b[0m   seen_names \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n\u001b[0;32m    204\u001b[0m   concrete_function\u001b[38;5;241m.\u001b[39m_arg_keywords \u001b[38;5;241m=\u001b[39m []  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n",
      "File \u001b[1;32m~\\.conda\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compiler.py:166\u001b[0m, in \u001b[0;36mTracingCompiler._maybe_define_concrete_function\u001b[1;34m(self, args, kwargs)\u001b[0m\n\u001b[0;32m    163\u001b[0m   args \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput_signature\n\u001b[0;32m    164\u001b[0m   kwargs \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m--> 166\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_maybe_define_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\.conda\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compiler.py:396\u001b[0m, in \u001b[0;36mTracingCompiler._maybe_define_function\u001b[1;34m(self, args, kwargs)\u001b[0m\n\u001b[0;32m    393\u001b[0m   args \u001b[38;5;241m=\u001b[39m placeholder_bound_args\u001b[38;5;241m.\u001b[39margs\n\u001b[0;32m    394\u001b[0m kwargs \u001b[38;5;241m=\u001b[39m placeholder_bound_args\u001b[38;5;241m.\u001b[39mkwargs\n\u001b[1;32m--> 396\u001b[0m concrete_function \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_create_concrete_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    397\u001b[0m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc_graph\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    399\u001b[0m \u001b[38;5;66;03m# TODO(b/263520817): Remove access to private attribute.\u001b[39;00m\n\u001b[0;32m    400\u001b[0m graph_capture_container \u001b[38;5;241m=\u001b[39m concrete_function\u001b[38;5;241m.\u001b[39mgraph\u001b[38;5;241m.\u001b[39m_function_captures  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n",
      "File \u001b[1;32m~\\.conda\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compiler.py:300\u001b[0m, in \u001b[0;36mTracingCompiler._create_concrete_function\u001b[1;34m(self, args, kwargs, func_graph)\u001b[0m\n\u001b[0;32m    296\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    297\u001b[0m   arg_names \u001b[38;5;241m=\u001b[39m base_arg_names\n\u001b[0;32m    299\u001b[0m concrete_function \u001b[38;5;241m=\u001b[39m monomorphic_function\u001b[38;5;241m.\u001b[39mConcreteFunction(\n\u001b[1;32m--> 300\u001b[0m     \u001b[43mfunc_graph_module\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunc_graph_from_py_func\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    301\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    302\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_python_function\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    303\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    304\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    305\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    306\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfunc_graph\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunc_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    307\u001b[0m \u001b[43m        \u001b[49m\u001b[43mautograph\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_autograph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    308\u001b[0m \u001b[43m        \u001b[49m\u001b[43mautograph_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_autograph_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    309\u001b[0m \u001b[43m        \u001b[49m\u001b[43marg_names\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43marg_names\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    310\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcapture_by_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_capture_by_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    311\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcreate_placeholders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m,\n\u001b[0;32m    312\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_function_attributes,\n\u001b[0;32m    313\u001b[0m     spec\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_spec,\n\u001b[0;32m    314\u001b[0m     \u001b[38;5;66;03m# Tell the ConcreteFunction to clean up its graph once it goes out of\u001b[39;00m\n\u001b[0;32m    315\u001b[0m     \u001b[38;5;66;03m# scope. This is not the default behavior since it gets used in some\u001b[39;00m\n\u001b[0;32m    316\u001b[0m     \u001b[38;5;66;03m# places (like Keras) where the FuncGraph lives longer than the\u001b[39;00m\n\u001b[0;32m    317\u001b[0m     \u001b[38;5;66;03m# ConcreteFunction.\u001b[39;00m\n\u001b[0;32m    318\u001b[0m     shared_func_graph\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m    319\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m concrete_function\n",
      "File \u001b[1;32m~\\.conda\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py:1214\u001b[0m, in \u001b[0;36mfunc_graph_from_py_func\u001b[1;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, create_placeholders, acd_record_initial_resource_uses)\u001b[0m\n\u001b[0;32m   1211\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1212\u001b[0m   _, original_func \u001b[38;5;241m=\u001b[39m tf_decorator\u001b[38;5;241m.\u001b[39munwrap(python_func)\n\u001b[1;32m-> 1214\u001b[0m func_outputs \u001b[38;5;241m=\u001b[39m python_func(\u001b[38;5;241m*\u001b[39mfunc_args, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfunc_kwargs)\n\u001b[0;32m   1216\u001b[0m \u001b[38;5;66;03m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[39;00m\n\u001b[0;32m   1217\u001b[0m \u001b[38;5;66;03m# TensorArrays and `None`s.\u001b[39;00m\n\u001b[0;32m   1218\u001b[0m func_outputs \u001b[38;5;241m=\u001b[39m variable_utils\u001b[38;5;241m.\u001b[39mconvert_variables_to_tensors(func_outputs)\n",
      "File \u001b[1;32m~\\.conda\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\data\\ops\\structured_function.py:238\u001b[0m, in \u001b[0;36mStructuredFunctionWrapper.__init__.<locals>.trace_tf_function.<locals>.wrapped_fn\u001b[1;34m(*args)\u001b[0m\n\u001b[0;32m    232\u001b[0m \u001b[38;5;129m@eager_function\u001b[39m\u001b[38;5;241m.\u001b[39mdefun_with_attributes(\n\u001b[0;32m    233\u001b[0m     input_signature\u001b[38;5;241m=\u001b[39mstructure\u001b[38;5;241m.\u001b[39mget_flat_tensor_specs(\n\u001b[0;32m    234\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_input_structure),\n\u001b[0;32m    235\u001b[0m     autograph\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    236\u001b[0m     attributes\u001b[38;5;241m=\u001b[39mdefun_kwargs)\n\u001b[0;32m    237\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapped_fn\u001b[39m(\u001b[38;5;241m*\u001b[39margs):  \u001b[38;5;66;03m# pylint: disable=missing-docstring\u001b[39;00m\n\u001b[1;32m--> 238\u001b[0m   ret \u001b[38;5;241m=\u001b[39m \u001b[43mwrapper_helper\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    239\u001b[0m   ret \u001b[38;5;241m=\u001b[39m structure\u001b[38;5;241m.\u001b[39mto_tensor_list(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_output_structure, ret)\n\u001b[0;32m    240\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m [ops\u001b[38;5;241m.\u001b[39mconvert_to_tensor(t) \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m ret]\n",
      "File \u001b[1;32m~\\.conda\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\data\\ops\\structured_function.py:169\u001b[0m, in \u001b[0;36mStructuredFunctionWrapper.__init__.<locals>.wrapper_helper\u001b[1;34m(*args)\u001b[0m\n\u001b[0;32m    167\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _should_unpack(nested_args):\n\u001b[0;32m    168\u001b[0m   nested_args \u001b[38;5;241m=\u001b[39m (nested_args,)\n\u001b[1;32m--> 169\u001b[0m ret \u001b[38;5;241m=\u001b[39m \u001b[43mautograph\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtf_convert\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_func\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mag_ctx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mnested_args\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    170\u001b[0m ret \u001b[38;5;241m=\u001b[39m variable_utils\u001b[38;5;241m.\u001b[39mconvert_variables_to_tensors(ret)\n\u001b[0;32m    171\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _should_pack(ret):\n",
      "File \u001b[1;32m~\\.conda\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py:692\u001b[0m, in \u001b[0;36mconvert.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    690\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint:disable=broad-except\u001b[39;00m\n\u001b[0;32m    691\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(e, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mag_error_metadata\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[1;32m--> 692\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mag_error_metadata\u001b[38;5;241m.\u001b[39mto_exception(e)\n\u001b[0;32m    693\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    694\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m\n",
      "File \u001b[1;32m~\\.conda\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py:689\u001b[0m, in \u001b[0;36mconvert.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    687\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    688\u001b[0m   \u001b[38;5;28;01mwith\u001b[39;00m conversion_ctx:\n\u001b[1;32m--> 689\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mconverted_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    690\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint:disable=broad-except\u001b[39;00m\n\u001b[0;32m    691\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(e, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mag_error_metadata\u001b[39m\u001b[38;5;124m'\u001b[39m):\n",
      "File \u001b[1;32m~\\.conda\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py:439\u001b[0m, in \u001b[0;36mconverted_call\u001b[1;34m(f, args, kwargs, caller_fn_scope, options)\u001b[0m\n\u001b[0;32m    437\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    438\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m kwargs \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 439\u001b[0m     result \u001b[38;5;241m=\u001b[39m converted_f(\u001b[38;5;241m*\u001b[39meffective_args, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    440\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    441\u001b[0m     result \u001b[38;5;241m=\u001b[39m converted_f(\u001b[38;5;241m*\u001b[39meffective_args)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Temp\\__autograph_generated_file42nefkri.py:5\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.<lambda>\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minner_factory\u001b[39m(ag__):\n\u001b[1;32m----> 5\u001b[0m     tf__lam \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mlambda\u001b[39;00m x: \u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwith_function_scope\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mlscope\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mbook_embedding\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconverted_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbook_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlscope\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mbook_id\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mbook_id\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mlscope\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mSTD\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      6\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m tf__lam\n",
      "File \u001b[1;32m~\\.conda\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\autograph\\core\\function_wrappers.py:113\u001b[0m, in \u001b[0;36mwith_function_scope\u001b[1;34m(thunk, scope_name, options)\u001b[0m\n\u001b[0;32m    111\u001b[0m \u001b[38;5;124;03m\"\"\"Inline version of the FunctionScope context manager.\"\"\"\u001b[39;00m\n\u001b[0;32m    112\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m FunctionScope(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlambda_\u001b[39m\u001b[38;5;124m'\u001b[39m, scope_name, options) \u001b[38;5;28;01mas\u001b[39;00m scope:\n\u001b[1;32m--> 113\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mthunk\u001b[49m\u001b[43m(\u001b[49m\u001b[43mscope\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Temp\\__autograph_generated_file42nefkri.py:5\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.<lambda>\u001b[1;34m(lscope)\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minner_factory\u001b[39m(ag__):\n\u001b[1;32m----> 5\u001b[0m     tf__lam \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mlambda\u001b[39;00m x: ag__\u001b[38;5;241m.\u001b[39mwith_function_scope(\u001b[38;5;28;01mlambda\u001b[39;00m lscope: {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbook_embedding\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconverted_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbook_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlscope\u001b[49m\u001b[43m)\u001b[49m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbook_id\u001b[39m\u001b[38;5;124m'\u001b[39m: x[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbook_id\u001b[39m\u001b[38;5;124m'\u001b[39m]}, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlscope\u001b[39m\u001b[38;5;124m'\u001b[39m, ag__\u001b[38;5;241m.\u001b[39mSTD)\n\u001b[0;32m      6\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m tf__lam\n",
      "File \u001b[1;32m~\\.conda\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py:331\u001b[0m, in \u001b[0;36mconverted_call\u001b[1;34m(f, args, kwargs, caller_fn_scope, options)\u001b[0m\n\u001b[0;32m    329\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m conversion\u001b[38;5;241m.\u001b[39mis_in_allowlist_cache(f, options):\n\u001b[0;32m    330\u001b[0m   logging\u001b[38;5;241m.\u001b[39mlog(\u001b[38;5;241m2\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAllowlisted \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m: from cache\u001b[39m\u001b[38;5;124m'\u001b[39m, f)\n\u001b[1;32m--> 331\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_call_unconverted\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m    333\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ag_ctx\u001b[38;5;241m.\u001b[39mcontrol_status_ctx()\u001b[38;5;241m.\u001b[39mstatus \u001b[38;5;241m==\u001b[39m ag_ctx\u001b[38;5;241m.\u001b[39mStatus\u001b[38;5;241m.\u001b[39mDISABLED:\n\u001b[0;32m    334\u001b[0m   logging\u001b[38;5;241m.\u001b[39mlog(\u001b[38;5;241m2\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAllowlisted: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m: AutoGraph is disabled in context\u001b[39m\u001b[38;5;124m'\u001b[39m, f)\n",
      "File \u001b[1;32m~\\.conda\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py:459\u001b[0m, in \u001b[0;36m_call_unconverted\u001b[1;34m(f, args, kwargs, options, update_cache)\u001b[0m\n\u001b[0;32m    457\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m kwargs \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    458\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m f(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m--> 459\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\.conda\\envs\\tf\\lib\\site-packages\\keras\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\AppData\\Local\\Temp\\__autograph_generated_filedywseif7.py:12\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__call\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     11\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m---> 12\u001b[0m     retval_ \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(tf)\u001b[38;5;241m.\u001b[39mconcat, ([ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39mbook_embedding, (ag__\u001b[38;5;241m.\u001b[39mld(inputs)[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbook_id\u001b[39m\u001b[38;5;124m'\u001b[39m],), \u001b[38;5;28;01mNone\u001b[39;00m, fscope), ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39mtitle_embedding, (ag__\u001b[38;5;241m.\u001b[39mld(inputs)[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbook_title\u001b[39m\u001b[38;5;124m'\u001b[39m],), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)],), \u001b[38;5;28mdict\u001b[39m(axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m), fscope)\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[0;32m     14\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "\u001b[1;31mValueError\u001b[0m: in user code:\n\n    File \"C:\\Users\\awast\\AppData\\Local\\Temp\\ipykernel_79924\\1463076740.py\", line 2, in None  *\n        lambda x: {\"book_embedding\": model.book_model(x), \"book_id\": x[\"book_id\"]}\n    File \"C:\\Users\\awast\\.conda\\envs\\tf\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 70, in error_handler  **\n        raise e.with_traceback(filtered_tb) from None\n    File \"C:\\Users\\awast\\AppData\\Local\\Temp\\__autograph_generated_filedywseif7.py\", line 12, in tf__call\n        retval_ = ag__.converted_call(ag__.ld(tf).concat, ([ag__.converted_call(ag__.ld(self).book_embedding, (ag__.ld(inputs)['book_id'],), None, fscope), ag__.converted_call(ag__.ld(self).title_embedding, (ag__.ld(inputs)['book_title'],), None, fscope)],), dict(axis=1), fscope)\n\n    ValueError: Exception encountered when calling layer 'book_model_16' (type BookModel).\n    \n    in user code:\n    \n        File \"C:\\Users\\awast\\AppData\\Local\\Temp\\ipykernel_79924\\948094142.py\", line 28, in call  *\n            self.title_embedding(inputs[\"book_title\"]),\n        File \"C:\\Users\\awast\\.conda\\envs\\tf\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 70, in error_handler  **\n            raise e.with_traceback(filtered_tb) from None\n        File \"C:\\Users\\awast\\.conda\\envs\\tf\\lib\\site-packages\\keras\\engine\\input_spec.py\", line 235, in assert_input_compatibility\n            raise ValueError(\n    \n        ValueError: Exception encountered when calling layer 'sequential_112' (type Sequential).\n        \n        Input 0 of layer \"global_average_pooling1d_10\" is incompatible with the layer: expected ndim=3, found ndim=2. Full shape received: (None, 32)\n        \n        Call arguments received by layer 'sequential_112' (type Sequential):\n          • inputs=tf.Tensor(shape=(), dtype=string)\n          • training=None\n          • mask=None\n    \n    \n    Call arguments received by layer 'book_model_16' (type BookModel):\n      • inputs={'book_id': 'tf.Tensor(shape=(), dtype=string)', 'book_title': 'tf.Tensor(shape=(), dtype=string)'}\n"
     ]
    }
   ],
   "source": [
    "# Transform book titles into embeddings using the book_model\n",
    "test_map = tf_books_map.map(lambda x: {\"book_embedding\": model.book_model(x), \"book_id\": x[\"book_id\"]})\n",
    "\n",
    "# Use 'index_from_dataset'\n",
    "index.index_from_dataset(\n",
    "    tf_books_map.batch(100).map(lambda x: (x[\"book_title\"], x[\"book_id\"]))\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
